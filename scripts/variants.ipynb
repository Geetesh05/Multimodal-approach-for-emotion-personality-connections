{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, Input, BatchNormalization, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.optimizers import Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from albumentations import (\n",
    "    RandomRotate90,Flip\n",
    ")\n",
    "import scipy.io\n",
    "import difflib\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from scipy import spatial\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "print('This should list a GPU: ',tf.test.gpu_device_name())\n",
    "os.chdir('/home/xx652230/Downloads/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=64\n",
    "modele = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=5, activation='relu', input_shape=(120, 120, 1)),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=16, kernel_size=5, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "modele.load_weights(\"/home/xx652230/deap.hdf5\")\n",
    "modele.compile(optimizer='adam', loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "width, height = 48, 48\n",
    "modelf = Sequential([\n",
    "        Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1)),  # 1\n",
    "        Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1)),  # 1\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 2\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 3\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 4\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 5\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 3\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 4\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 5\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * 2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 6\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * 2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 7\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 8\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(2 * 2 * 2 * num_features, activation='relu'),  # 9\n",
    "        Dropout(0.4),\n",
    "        Dense(2 * 2 * num_features, activation='relu'),  # 10\n",
    "        Dropout(0.4),\n",
    "        Dense(2 * num_features, activation='relu'),  # 10\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(7, activation='softmax')\n",
    "\n",
    "])\n",
    "modelf.load_weights(\"./model/face/final_model_face.hdf5\") \n",
    "modelf.compile(optimizer='adam', loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extro=[[4.585985850208803e-15,0.21845765462726016,1.2004518046413182e-33, 0.0032726129400430133,2.88223566844931e-10],[4.617901587721846e-17, 2.8794632384214214e-05,0.7006698671272261,0.00030375642303191985,5.349446338041911e-29],[7.712894901000039e-26,6.793818882556078e-08,0.21594196027410054,7.898015419524533e-21,1.2083597473092602e-08],[2.029438337499281e-13,2.2545183913806833e-49,1.8604640313660267e-14,0.6551005018450482,6.454039690105326e-17],\n",
    "[0.09947992749667031,1.8188108286179053e-07,3.254135222599444e-08,7.636538797314128e-07,2.0234142068112048e-36]]\n",
    "probs=[[0.26,0.63,0.64,0.28,0.29],[0.25,0.64,0.67,0.39,0.25],[0.18, 0.57, 0.66, 0.36, 0.32],[0.19, 0.61, 0.49, 0.28, 0.22],[0.24, 0.58, 0.60, 0.17, 0.4]]\n",
    "pb=np.array(extro)*np.array(probs)\n",
    "ex=[]\n",
    "for i in range(5):\n",
    "    ex.append(np.sum(pb[i]))\n",
    "\n",
    "\n",
    "def new_loss(y_pred,y_actual):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    l1=cce(y_pred,y_actual) \n",
    "    lall=[0.8*l1+0.2*ex[i] for i in range(5)] \n",
    "    lout=keras.backend.max(lall)\n",
    "    return lout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b0=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined0 = concatenate([a0.output, b0.output])\n",
    "z0 = Dense(256, activation=\"relu\")(combined0)\n",
    "z0 = Dense(5, activation=\"softmax\")(z0)\n",
    "model0 = Model(inputs=[a0.input, b0.input], outputs=z0)\n",
    "for i in range(len(model0.layers)-2):\n",
    "    model0.layers[i].trainable=False\n",
    "    \n",
    "model0.compile(loss=new_loss, optimizer='adam',metrics=['accuracy'])\n",
    "model0.load_weights(\"./results/cnnconcat_p30.hdf5\") \n",
    "#model0.load_weights(\"./redo/cnnpersonality.hdf5\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=[i*0.30 for i in model0.layers[31].get_weights()] #eeg\n",
    "model0.layers[31].set_weights(w1)\n",
    "w2=[i*0.70 for i in model0.layers[32].get_weights()] #face\n",
    "model0.layers[32].set_weights(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path,d1,d2):\n",
    "    file_read=pd.read_csv(path)\n",
    "    construct=[]\n",
    "    #construct.append([i for i in file_read.columns])\n",
    "    for i in range(len(file_read)):\n",
    "        construct.append(file_read.loc[i,:])\n",
    "    if d2!=0:    \n",
    "        file1=np.reshape(np.array(construct)[39:],(len(construct)-39,d1,d2,1))  \n",
    "        return file1\n",
    "    else:\n",
    "        file1=np.reshape(np.array(construct)[39:],(len(construct)-39,d1))\n",
    "        return file1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 1: CNN concate variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train and test data\n",
    "imps=[\"eeg\",\"face\",\"quad\"]\n",
    "eeg=[]\n",
    "face=[]\n",
    "quad_out=[]\n",
    "score_out=[]\n",
    "model_out=[]\n",
    "eeg1=[]\n",
    "face1=[]\n",
    "quad_out1=[]\n",
    "score_out1=[]\n",
    "model_out1=[]\n",
    "for j in range(1,31):\n",
    "    notin=[8,12,28]\n",
    "    if j not in notin:\n",
    "      if j<10: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                eeg.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P0\"+str(j)+\".csv\",120,120)) \n",
    "                eeg1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",120,120))     \n",
    "\n",
    "            elif i==\"face\":   \n",
    "                face.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P0\"+str(j)+\".csv\",48,48))\n",
    "                face1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",48,48))\n",
    "\n",
    "            elif i==\"quad\":\n",
    "                quad_out.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P0\"+str(j)+\".csv\",5,0))\n",
    "                quad_out1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",5,0))\n",
    "\n",
    "          \n",
    "      elif  j>9: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                eeg.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",120,120))    \n",
    "                eeg1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",120,120))     \n",
    "\n",
    "            elif i==\"face\":   \n",
    "                face.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",48,48))\n",
    "                face1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",48,48))\n",
    "\n",
    "            elif i==\"quad\":\n",
    "                quad_out.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",5,0))\n",
    "                quad_out1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",5,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=[i for i range(len(eeg))]\n",
    "np.random.shuffle(num)\n",
    "t1=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=np.concatenate([eeg[i] for i in t1])\n",
    "x2_train=np.concatenate([face[i] for i in t1])\n",
    "y_train=np.concatenate([quad_out[i] for i in t1])\n",
    "x1_test=np.concatenate([eeg1[i] for i in t2])\n",
    "x2_test=np.concatenate([face1[i] for i in t2])\n",
    "y_test=np.concatenate([quad_out1[i] for i in t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.fit([np.array(x1_train),np.array(x2_train)],np.array(y_train),validation_data=([np.array(x1_test),np.array(x2_test)],np.array(y_test)),batch_size=256,epochs=10)\n",
    "emotion_list = [\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Neutral\"]\n",
    "c1=model0.predict([np.array(x1_test),np.array(x2_test)])\n",
    "c2=np.argmax(c1,axis=1)\n",
    "y_pred_classes=keras.utils.to_categorical(np.array(c2))\n",
    "conf_matrix = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(np.array(y_pred_classes),axis=1), normalize = 'true')\n",
    "df_conf = pd.DataFrame(conf_matrix, index = [i for i in emotion_list],\n",
    "                  columns = [i for i in emotion_list])\n",
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(df_conf, annot=True, cmap = 'Blues', fmt = '.1', cbar = False)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.save_weights(\"./redo/cnnpersonality.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 2: CNN-LSTM variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training set(group of 10 participants)\n",
    "imps=[\"eeg\",\"face\",\"quad\"]\n",
    "eeg=[]\n",
    "face=[]\n",
    "quad_out=[]\n",
    "score_out=[]\n",
    "model_out=[]\n",
    "for i in imps:\n",
    "    for j in range(1,3):\n",
    "       #if j!=2: \n",
    "        if i==\"eeg\":\n",
    "            eeg.append(read_csv(\"./SortedSamples/first10/\"+str(i)+str(j)+\"0.csv\",120,120))\n",
    "        elif i==\"face\":   \n",
    "            face.append(read_csv(\"./SortedSamples/first10/\"+str(i)+str(j)+\"0.csv\",48,48))\n",
    "        elif i==\"quad\":\n",
    "            quad_out.append(read_csv(\"./SortedSamples/first10/\"+str(i)+str(j)+\"0.csv\",5,0))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading testing set(group of 10 participants)\n",
    "imps=[\"eeg\",\"face\",\"quad\"]\n",
    "eeg1=[]\n",
    "face1=[]\n",
    "quad_out1=[]\n",
    "score_out1=[]\n",
    "model_out1=[]\n",
    "for i in imps:\n",
    "    for j in range(3,4):\n",
    "       #if j!=2: \n",
    "        if i==\"eeg\":\n",
    "            eeg1.append(read_csv(\"./redo/\"+str(i)+str(j)+\"0.csv\",120,120))\n",
    "        elif i==\"face\":   \n",
    "            face1.append(read_csv(\"./redo/\"+str(i)+str(j)+\"0.csv\",48,48))\n",
    "        elif i==\"quad\":\n",
    "            quad_out1.append(read_csv(\"./redo/\"+str(i)+str(j)+\"0.csv\",5,0))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed,Reshape\n",
    "a=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "video=Input(shape=(None,120,120,1))\n",
    "video1=Input(shape=(None,48,48,1))\n",
    "#b=Model(inputs=model_dude.inputs,outputs=model_dude.layers[-8].output)\n",
    "mod=Sequential()\n",
    "mod.add(video)\n",
    "mod.add(TimeDistributed(a))\n",
    "#mod.add(TimeDistributed(Flatten()))\n",
    "mod.add(LSTM(128,return_sequences=True))\n",
    "mod.add(TimeDistributed(Dense(128, activation=\"relu\",name=\"eeg\")))\n",
    "\n",
    "b=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "\n",
    "#b=Model(inputs=model_dude.inputs,outputs=model_dude.layers[-8].output)\n",
    "mod1=Sequential()\n",
    "mod1.add(video1)\n",
    "mod1.add(TimeDistributed(b))\n",
    "#mod1.add(TimeDistributed(Flatten()))\n",
    "mod1.add(LSTM(128,return_sequences=True))\n",
    "mod1.add(TimeDistributed(Dense(128, activation=\"relu\"),name=\"face\"))\n",
    "cont=concatenate([mod.output,mod1.output])\n",
    "z=TimeDistributed(Dense(128, activation=\"relu\"))(cont)\n",
    "z =TimeDistributed(Dense(5,activation=\"softmax\"))(z)\n",
    "model_dope=Model(inputs=[mod.input,mod1.input],outputs=z)\n",
    "for i in range(len(model_dope.layers)-8):\n",
    "    model_dope.layers[i].trainable=False\n",
    "model_dope.load_weights(\"./results/cnnlstmconcat_p30.hdf5\")\n",
    "model_dope.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data, steps = 40):  \n",
    "    docX, docY = [], []\n",
    "    for i in range(0, int(data.shape[0]/steps-1)):\n",
    "        docX.append(data[i*steps:(i+1)*steps,:])\n",
    "        #docY.append(data[(i*steps+1):((i+1)*steps+1),:])\n",
    "    return np.array(docX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx1=_load_data(np.array(x1_train))\n",
    "xx2=_load_data(np.array(x2_train))\n",
    "yy1=_load_data(np.array(y_train))\n",
    "xx4=_load_data(np.array(x1_test))\n",
    "xx5=_load_data(np.array(x2_test))\n",
    "yy6=_load_data(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_dope.fit([np.array(xx1)[:200],np.array(xx2)[:200]], np.array(yy1)[:200], validation_data=([np.array(xx4)[:50],np.array(xx5)[:50]], np.array(yy6)[:50]),epochs=10, verbose=1,steps_per_epoch=10)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=[i*0.3 for i in model_dope.layers[6].get_weights()] #eeg\n",
    "model_dope.layers[6].set_weights(w1)\n",
    "w2=[i*0.7 for i in model_dope.layers[7].get_weights()] #face\n",
    "model_dope.layers[7].set_weights(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dope.evaluate([np.array(xx4),np.array(xx5)],np.array(yy6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list=[\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Neutral\"]\n",
    "ytest1=[]\n",
    "ytest2=[]\n",
    "c1=model_dope.predict([np.array(xx4),np.array(xx5)])\n",
    "for i in range(len(c1)):\n",
    "    for j in range(len(c1[i])):\n",
    "            ytest1.append(yy6[i][j])\n",
    "            ytest2.append(c1[i][j])\n",
    "\n",
    "y_pred_classes=np.argmax(ytest2,axis=1)\n",
    "y_pred_classes = keras.utils.to_categorical(y_pred_classes)\n",
    "conf_matrix = confusion_matrix(np.argmax(np.array(ytest1), axis=1), np.argmax(np.array(y_pred_classes),axis=1), normalize = 'true')\n",
    "df_conf = pd.DataFrame(conf_matrix, index = [i for i in emotion_list],\n",
    "                  columns = [i for i in emotion_list])\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(df_conf, annot=True, cmap = 'Blues', fmt = '.1', cbar = False)\n",
    "plt.savefig(\"./redo/lstmbaseline1.jpg\")\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“final”",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
