{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should list a GPU:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, Input, BatchNormalization, concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.optimizers import Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from albumentations import (\n",
    "    RandomRotate90,Flip\n",
    ")\n",
    "import scipy.io\n",
    "import difflib\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from scipy import spatial\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "print('This should list a GPU: ',tf.test.gpu_device_name())\n",
    "os.chdir('/home/xx652230/Downloads/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.read_excel(\"./amigos/personalities.xlsx\")\n",
    "traits=[]\n",
    "for i in range(1,31):\n",
    "    if i!=8 and i!=28:\n",
    "        #if t[i][0]>5:\n",
    "            trait=[t[i][j] for j in range(5)]\n",
    "            traits.append(trait)\n",
    "        #else:\n",
    "         #   traits.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index={}\n",
    "for i in range(0,31):\n",
    "    if i>7 and i<12:\n",
    "        index[i]=i-2\n",
    "    elif i> 12 and i<28:\n",
    "        index[i]=i-2\n",
    "    elif i>28:\n",
    "        index[i]=i-3\n",
    "    else:\n",
    "        index[i]=i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=64\n",
    "modele = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=5, activation='relu', input_shape=(120, 120, 1)),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=16, kernel_size=5, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "modele.load_weights(\"/home/xx652230/deap.hdf5\")\n",
    "modele.compile(optimizer='adam', loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "width, height = 48, 48\n",
    "modelf = Sequential([\n",
    "        Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1)),  # 1\n",
    "        Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1)),  # 1\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 2\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 3\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 4\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 5\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 3\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 4\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 5\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Conv2D(2 * 2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 6\n",
    "        BatchNormalization(),\n",
    "        Conv2D(2 * 2 * 2 * num_features, kernel_size=(3, 3), activation='relu', padding='same'),  # 7\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),  # 8\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(2 * 2 * 2 * num_features, activation='relu'),  # 9\n",
    "        Dropout(0.4),\n",
    "        Dense(2 * 2 * num_features, activation='relu'),  # 10\n",
    "        Dropout(0.4),\n",
    "        Dense(2 * num_features, activation='relu'),  # 10\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(7, activation='softmax')\n",
    "\n",
    "])\n",
    "modelf.load_weights(\"./model/face/final_model_face.hdf5\") \n",
    "modelf.compile(optimizer='adam', loss='categorical_crossentropy' , metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b1=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined = concatenate([a1.output, b1.output])\n",
    "z1 = Dense(256, activation=\"relu\",)(combined)\n",
    "z1 = Dense(1,activation=\"sigmoid\")(z1)\n",
    "model2 = Model(inputs=[a1.input, b1.input], outputs=z1)\n",
    "for i in range(len(model2.layers)-3):\n",
    "    model2.layers[i].trainable=False\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model2.load_weights(\"./loss/creative.hdf5\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed,Reshape\n",
    "a=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "video=Input(shape=(None,120,120,1))\n",
    "video1=Input(shape=(None,48,48,1))\n",
    "#b=Model(inputs=model_dude.inputs,outputs=model_dude.layers[-8].output)\n",
    "mod=Sequential()\n",
    "mod.add(video)\n",
    "mod.add(TimeDistributed(a))\n",
    "#mod.add(TimeDistributed(Flatten()))\n",
    "mod.add(LSTM(128,return_sequences=True))\n",
    "mod.add(TimeDistributed(Dense(128, activation=\"relu\",name=\"eeg\")))\n",
    "\n",
    "b=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "\n",
    "#b=Model(inputs=model_dude.inputs,outputs=model_dude.layers[-8].output)\n",
    "mod1=Sequential()\n",
    "mod1.add(video1)\n",
    "mod1.add(TimeDistributed(b))\n",
    "#mod1.add(TimeDistributed(Flatten()))\n",
    "mod1.add(LSTM(128,return_sequences=True))\n",
    "mod1.add(TimeDistributed(Dense(128, activation=\"relu\"),name=\"face\"))\n",
    "cont=concatenate([mod.output,mod1.output])\n",
    "z=TimeDistributed(Dense(128, activation=\"relu\"))(cont)\n",
    "z =TimeDistributed(Dense(1,activation=\"sigmoid\"))(z)\n",
    "model_dope=Model(inputs=[mod.input,mod1.input],outputs=z)\n",
    "for i in range(len(model_dope.layers)-8):\n",
    "    model_dope.layers[i].trainable=False\n",
    "#model_dope.load_weights(\"./results/cnnlstmconcat_p30.hdf5\")\n",
    "model_dope.compile(optimizer=\"adam\", loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "#w1=[i*0.4 for i in model_dope.layers[6].get_weights()] #eeg\n",
    "#model_dope.layers[6].set_weights(w1)\n",
    "#w2=[i*0.6 for i in model_dope.layers[7].get_weights()] #face\n",
    "#model_dope.layers[7].set_weights(w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path,d1,d2):\n",
    "    file_read=pd.read_csv(path)\n",
    "    construct=[]\n",
    "    #construct.append([i for i in file_read.columns])\n",
    "    for i in range(len(file_read)):\n",
    "        construct.append(file_read.loc[i,:])\n",
    "    if d2!=0:    \n",
    "        file1=np.reshape(np.array(construct)[39:],(len(construct)-39,d1,d2,1))  \n",
    "        return file1\n",
    "    else:\n",
    "        file1=np.reshape(np.array(construct)[39:],(len(construct)-39,d1))\n",
    "        return file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def round_off(sample):\n",
    "    trait_final=0.0\n",
    "    #for i in range(len(sample)):\n",
    "    if sample[0]>5:\n",
    "        trait_final=1.0\n",
    "    else:\n",
    "        trait_final=0.0\n",
    "    return trait_final \n",
    "def round_off1(sample):\n",
    "    trait_final=[0.0]*5\n",
    "    t=np.where(sample==max(sample))\n",
    "    for i in t[0]:\n",
    "        trait_final[i]=1.0\n",
    "    return trait_final\n",
    "\n",
    "def trait_output(see_file,ind):\n",
    "    y_person=[]\n",
    "    length=len(see_file)\n",
    "    for i in range(length):\n",
    "        y_person.append(round_off(traits[ind]))\n",
    "        \n",
    "    return y_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps=[\"eeg\",\"face\"]\n",
    "eeg=[]\n",
    "face=[]\n",
    "eeg1=[]\n",
    "face1=[]\n",
    "for j in range(1,21):\n",
    "    notin=[8,12,28]\n",
    "    if j not in notin :\n",
    "      if j<10: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                eeg.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P0\"+str(j)+\".csv\",120,120))  \n",
    "                eeg1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",120,120))     \n",
    "\n",
    "            elif i==\"face\":   \n",
    "                face.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P0\"+str(j)+\".csv\",48,48))\n",
    "                face1.append(read_csv(\"./t/\"+str(i)+\"P0\"+str(j)+\".csv\",48,48))\n",
    "\n",
    "           \n",
    "      elif  j>9: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                eeg.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",120,120))\n",
    "                eeg1.append(read_csv(\"./t/\"+str(i)+\"P\"+str(j)+\".csv\",120,120))     \n",
    "\n",
    "              \n",
    "            elif i==\"face\":   \n",
    "                face.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",48,48))\n",
    "                face1.append(read_csv(\"./t/\"+str(i)+\"P\"+str(j)+\".csv\",48,48))\n",
    "\n",
    "            elif i==\"quad\":\n",
    "                quad_out.append(read_csv(\"./SortedSamples/participants/\"+str(i)+\"P\"+str(j)+\".csv\",5,0))\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a1b85040439b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0my_traits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0my_traits1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "imps=[\"eeg\",\"face\",\"quad\",\"model\"]\n",
    "y_traits=[]\n",
    "y_traits1=[]\n",
    "for j in range(1,21):\n",
    "    notin=[8,12,28]\n",
    "    if j not in notin :\n",
    "      if j<10: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                if j>8:\n",
    "                    y_traits.append(trait_output(eeg[j-2],index[j]))\n",
    "                    y_traits1.append(trait_output(eeg1[j-2],index[j]))\n",
    "\n",
    "                else:   \n",
    "                    y_traits.append(trait_output(eeg[j-1],index[j]))\n",
    "                    y_traits1.append(trait_output(eeg1[j-1],index[j]))\n",
    "\n",
    "\n",
    "      elif  j>9: \n",
    "        for i in imps:\n",
    "            if i==\"eeg\":\n",
    "                if j>11 and j<29:\n",
    "                    y_traits.append(trait_output(eeg[j-3],index[j]))\n",
    "                    y_traits1.append(trait_output(eeg1[j-3],index[j]))\n",
    "\n",
    "                elif j>27:   \n",
    "                    y_traits.append(trait_output(eeg[j-4],index[j]))\n",
    "                    y_traits1.append(trait_output(eeg1[j-4],index[j]))\n",
    "\n",
    "                elif j<12:   \n",
    "                    y_traits.append(trait_output(eeg[j-2],index[j]))    \n",
    "                    y_traits1.append(trait_output(eeg1[j-2],index[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "acc_per_fold=[]\n",
    "loss_per_fold=[]\n",
    "for train_index,test_index in kf.split(np.array(eeg_copy)):\n",
    "    x1=np.concatenate([eeg_copy[i] for i in train_index]) \n",
    "    x2=np.concatenate([face_copy[i] for i in train_index])\n",
    "    y1=np.concatenate([y_traits[i] for i in train_index])\n",
    "    x4=np.concatenate([eeg_copy[i] for i in test_index])\n",
    "    x5=np.concatenate([face_copy[i] for i in test_index])\n",
    "    y6=np.concatenate([y_traits[i] for i in test_index])\n",
    "    history = model2.fit([np.array(x1),np.array(x2)], np.array(y1), validation_data=([np.array(x4),np.array(x5)], np.array(y6)),epochs=15, verbose=1,batch_size=256)  \n",
    "    scores = model2.evaluate([np.array(x4),np.array(x5)], np.array(y6), verbose=0)\n",
    "    print(f'Score for fold : {model2.metrics_names[0]} of {scores[0]}; {model2.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data, steps = 40):  \n",
    "    docX, docY = [], []\n",
    "    for i in range(0, int(data.shape[0]/steps-1)):\n",
    "        docX.append(data[i*steps:(i+1)*steps,:])\n",
    "        #docY.append(data[(i*steps+1):((i+1)*steps+1),:])\n",
    "    return np.array(docX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data1(data, steps = 40):  \n",
    "    docX, docY = [], []\n",
    "    for i in range(0, int(data.shape[0]/steps-1)):\n",
    "        docX.append(data[i*steps:(i+1)*steps])\n",
    "        #docY.append(data[(i*steps+1):((i+1)*steps+1),:])\n",
    "    return np.array(docX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "acc_per_fold=[]\n",
    "loss_per_fold=[]\n",
    "matrix=[]\n",
    "for train_index,test_index in kf.split(np.array(eeg)):\n",
    "    print(train_index,test_index)\n",
    "    emotion_list=[\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Neutral\"]\n",
    "    x1=np.concatenate([eeg[i] for i in train_index])  \n",
    "    x2=np.concatenate([face[i] for i in train_index])\n",
    "    y1=np.concatenate([y_traits[i] for i in train_index])\n",
    "    x4=np.concatenate([eeg1[i] for i in test_index])\n",
    "    x5=np.concatenate([face1[i] for i in test_index])\n",
    "    y6=np.concatenate([y_traits1[i] for i in test_index])\n",
    "    xx1=_load_data(np.array(x1))\n",
    "    xx2=_load_data(np.array(x2))\n",
    "    yy1=_load_data1(np.array(y1))\n",
    "    xx4=_load_data(np.array(x4))\n",
    "    xx5=_load_data(np.array(x5))\n",
    "    yy6=_load_data1(np.array(y6))\n",
    "    history = model_dope.fit([np.array(xx1),np.array(xx2)], np.array(yy1), validation_data=([np.array(xx4),np.array(xx5)], np.array(yy6)),epochs=5, verbose=1,steps_per_epoch=10)  \n",
    "    scores = model_dope.evaluate([np.array(xx4),np.array(xx5)], np.array(yy6), verbose=0)          \n",
    "    print(f'Score for fold : {model_dope.metrics_names[0]} of {scores[0]}; {model_dope.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Emotion personality relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b1=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined1 = concatenate([a1.output, b1.output])\n",
    "z1 = Dense(256, activation=\"relu\")(combined1)\n",
    "z1 = Dense(1, activation=\"sigmoid\")(z1)\n",
    "model1 = Model(inputs=[a1.input, b1.input], outputs=z1)\n",
    "for i in range(len(model1.layers)-3):\n",
    "    model1.layers[i].trainable=False\n",
    "    \n",
    "model1.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "model1.load_weights(\"./loss/extroversion.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b2=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined2 = concatenate([a2.output, b2.output])\n",
    "z2 = Dense(256, activation=\"relu\")(combined2)\n",
    "z2 = Dense(1, activation=\"sigmoid\")(z2)\n",
    "model2 = Model(inputs=[a2.input, b2.input], outputs=z2)\n",
    "for i in range(len(model2.layers)-3):\n",
    "    model2.layers[i].trainable=False\n",
    "    \n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "model2.load_weights(\"./loss/agreeable.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b3=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined3 = concatenate([a3.output, b3.output])\n",
    "z3 = Dense(256, activation=\"relu\")(combined3)\n",
    "z3 = Dense(1, activation=\"sigmoid\")(z3)\n",
    "model3 = Model(inputs=[a3.input, b3.input], outputs=z3)\n",
    "for i in range(len(model3.layers)-3):\n",
    "    model3.layers[i].trainable=False\n",
    "    \n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "model3.load_weights(\"./loss/conscientious.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b4=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined4 = concatenate([a4.output, b4.output])\n",
    "z4 = Dense(256, activation=\"relu\")(combined4)\n",
    "z4 = Dense(1, activation=\"sigmoid\")(z4)\n",
    "model4 = Model(inputs=[a4.input, b4.input], outputs=z4)\n",
    "for i in range(len(model4.layers)-3):\n",
    "    model4.layers[i].trainable=False\n",
    "    \n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "model4.load_weights(\"./loss/emotional.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a5=Model(inputs=modele.inputs,outputs=modele.layers[-4].output)\n",
    "b5=Model(inputs=modelf.inputs,outputs=modelf.layers[-8].output)\n",
    "combined5 = concatenate([a5.output, b5.output])\n",
    "z5 = Dense(256, activation=\"relu\")(combined5)\n",
    "z5 = Dense(1, activation=\"sigmoid\")(z5)\n",
    "model5 = Model(inputs=[a5.input, b5.input], outputs=z5)\n",
    "for i in range(len(model5.layers)-3):\n",
    "    model5.layers[i].trainable=False\n",
    "    \n",
    "model5.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "model5.load_weights(\"./loss/creative.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1all=np.concatenate([eeg1[i] for i in range(len(eeg1))])\n",
    "x2all=np.concatenate([face1[i] for i in range(len(eeg1))])\n",
    "#y1=np.concatenate([y_traits[i] for i in  l3])\n",
    "#x4=np.concatenate([eeg1[i] for i in  l2])\n",
    "#x5=np.concatenate([face1[i] for i in  l2])\n",
    "#y6=np.concatenate([y_traits[i] for i in  l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import corrcoef\n",
    "\n",
    "quad1=[]\n",
    "quad2=[]\n",
    "quad3=[]\n",
    "quad4=[]\n",
    "neutral=[]\n",
    "quad1e=[]\n",
    "quad2e=[]\n",
    "quad3e=[]\n",
    "quad4e=[]\n",
    "neutrale=[]\n",
    "personal1=model1.predict([np.array(x1all),np.array(x2all)])\n",
    "personal2=model2.predict([np.array(x1all),np.array(x2all)])\n",
    "personal3=model3.predict([np.array(x1all),np.array(x2all)])\n",
    "personal4=model4.predict([np.array(x1all),np.array(x2all)])\n",
    "personal5=model5.predict([np.array(x1all),np.array(x2all)])\n",
    "alls=[[personal1[i][0],personal2[i][0],personal3[i][0],personal4[i][0],personal5[i][0]] for i in range(len(personal1))]\n",
    "personal=modele.predict(np.array(x1all))\n",
    "for i in range(len(personal)):\n",
    "    index=np.where(personal[i]==max(personal[i]))\n",
    "    if index[0][0]==0:\n",
    "        quad1.append([j for j in alls[i]])\n",
    "        quad1e.append([j for j in personal[i]])\n",
    "        #quad1e.append([1,0,0,0,0])\n",
    "    elif index[0][0]==1:\n",
    "        quad2.append([j for j in alls[i]])\n",
    "        quad2e.append([j for j in personal[i]])\n",
    "        #quad2e.append([0,1,0,0,0])\n",
    "        \n",
    "    elif index[0][0]==2:\n",
    "        quad3.append([j for j in alls[i]])\n",
    "        quad3e.append([j for j in personal[i]])\n",
    "        #quad3e.append([0,0,1,0,0])\n",
    "\n",
    "    elif index[0][0]==3:\n",
    "        quad4.append([j for j in alls[i]])\n",
    "        quad4e.append([j for j in personal[i]])\n",
    "        #quad4e.append([0,0,0,1,0])\n",
    "\n",
    "    else:\n",
    "        neutral.append([j for j in alls[i]])\n",
    "        neutrale.append([j for j in personal[i]])\n",
    "        #neutrale.append([0,0,0,0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "k=[]\n",
    "d=[]\n",
    "for i in range(len(neutral)):\n",
    "    p1,p2=pearsonr(neutral[i],neutrale[i])\n",
    "    if p2<0.05:\n",
    "        k.append(neutral[i])\n",
    "        d.append([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "for it in range(5):\n",
    "    dic[it]=0\n",
    "for j in k:\n",
    "    t=np.where(j==max(j))[0][0]\n",
    "    dic[t]=dic[t]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 19, 2: 12, 3: 2, 4: 2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“final”",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
